{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118B - Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Jay Buensuceso\n",
    "- Mabel Szeto\n",
    "- Joshua Lapidario\n",
    "- Sialoi Taa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "This section should be short and clearly stated. It should be a single paragraph <200 words.  It should summarize: \n",
    "- what your goal/problem is\n",
    "- what the data used represents and how they are measured\n",
    "- what you will be doing with the data\n",
    "- how performance/success will be measured\n",
    "\n",
    "We will be making a shoe detection model that would identify the shoe, then return the lowest price of it based on the popular shops online. The problem is handled two ways, an image classification neural network such as VCCNet would determine what kind of shoe it is. We then run some sort of clustering on it to cluster it based on whatever hyperparameter we decide on (i.e. brand, shoe type, etc.). Those parameters would be used to search for that specific pair online and return the cheapest cost for that pair of shoes. The cost portion would be a search algorithm/scrape on a set of sites. The clustering idea is there so it fits within the requirements of using unsupervised learning, but also further exploring any hidden similarities and contrasts between different shoes and shoe types beyond the context of supervised labeling. We are measuring accuracy by comparing our results with the actual price. For our unsupervised learning method, we will take into account the Rand Index and Adjusted Rand Index scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Fill in the background and discuss the kind of prior work that has gone on in this research area here. **Use inline citation** to specify which references support which statements.  You can do that through HTML footnotes (demonstrated here). I used to reccommend Markdown footnotes (google is your friend) because they are simpler but recently I have had some problems with them working for me whereas HTML ones always work so far. So use the method that works for you, but do use inline citations.\n",
    "\n",
    "Here is an example of inline citation. After government genocide in the 20th century, real birds were replaced with surveillance drones designed to look just like birds<a name=\"lorenz\"></a>[<sup>[1]</sup>](#lorenznote). Use a minimum of 2 or 3 citations, but we prefer more <a name=\"admonish\"></a>[<sup>[2]</sup>](#admonishnote). You need enough citations to fully explain and back up important facts. \n",
    "\n",
    "Remeber you are trying to explain why someone would want to answer your question or why your hypothesis is in the form that you've stated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "We are making a project to help you when you identify a pair of shoes but don’t know the name of them and want to know the cheapest price those shoes can be bought at. The algorithm will take pictures of shoes as input. We will be utilizing an image classification neural network such as VCCNet to determine what kind of shoe it is. Afterwards, we will make a clustering algorithm that will cluster images by brand. The identified shoe type and brand will be inserted into a search algorithm in order to optimize what sites it will look at, from the resulting sites we can scrape for prices and compare to find the lowest price from resale or the manufacturer's suggested retail price (msrp)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "- https://www.kaggle.com/datasets/die9origephit/nike-adidas-and-converse-imaged  The dataset contains 2 folders: one with the test data and the other one with training data. The test dataset contains 114 images and the training dataset contains 711 images. The images have a resolution of 240x240 pixels in RGB color model. Both the folders contain 3 classes: Adidas, Converse, and Nike, and have the same number of images per brand. Image content varies by the number of shoes, background, orientation, and some are being worn in the picture. \n",
    "- https://www.kaggle.com/datasets/ifeanyinneji/nike-adidas-shoes-for-image-classification-dataset/data The dataset contains 3 folders: test, train, and validation data. All folders contain 2 classes: adidas and nike. 30 images of shoes from each brand for testing, 230 images from each brand for training, 27 images for Adidas shoes and 28 Nike for the validation. Some of the images have backgrounds and some only have white in the background, orientation of shoes in the images vary. This set also comes with labels for the images in a csv.\n",
    "- https://www.kaggle.com/datasets/utkarshsaxenadn/shoes-classification-dataset-13k-images  The dataset has 5 classes: ballet flat, boat shoes, brogues, clogs, and sneakers. In the test set there are 1,215 images, the training set has 10,000 images, and the validation set has 2,500 images. Images in the dataset vary in orientation, backgrounds vary, some images of the shoes are being worn, and photos have varying numbers of shoes in them.\n",
    "- https://www.kaggle.com/datasets/noobyogi0100/shoe-dataset  This dataset consists of 6 classes of shoes: boots, sneakers, flip flops, loafers, sandals, and soccer shoes. It contains 249 images of each shoe type in the training set and 50 of each type in the validation set. The size of the images is variable but the format of each file is jpeg."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "In this section, clearly describe a solution to the problem. The solution should be applicable to the project domain and appropriate for the dataset(s) or input(s) given. Provide enough detail (e.g., algorithmic description and/or theoretical properties) to convince us that your solution is applicable. Why might your solution work? Make sure to describe how the solution will be tested.  \n",
    "\n",
    "If you know details already, describe how (e.g., library used, function calls) you plan to implement the solution in a way that is reproducible.\n",
    "\n",
    "If it is appropriate to the problem statement, describe a benchmark model<a name=\"sota\"></a>[<sup>[3]</sup>](#sotanote) against which your solution will be compared. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "Propose at least one evaluation metric that can be used to quantify the performance of both the benchmark model and the solution model. The evaluation metric(s) you propose should be appropriate given the context of the data, the problem statement, and the intended solution. Describe how the evaluation metric(s) are derived and provide an example of their mathematical representations (if applicable). Complex evaluation metrics should be clearly defined and quantifiable (can be expressed in mathematical or logical terms)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with any computer vision and machine learning problem, we need to be considerate with the consent and privacy of any individuals appearing within or affiliated with the dataset. We will ensure that the data we use for our project does not infringe upon anyone’s privacy or personal information, such as excluding faces and any indicators of personal addresses or locations from images we obtain. We will not be scraping data from sites that have a paywall, require password login to view, or any sites that restrict this type of data collection in their terms of service. The images and data that we will be scraping for are publicly accessible on the internet. We will be scraping only for the initial data collection part of our project to minimize load on the website's servers and spread the volume that we scrape across different sites to avoid disrupting the service for other users. We are not making generative AI that creates new images from the images in our datasets.\n",
    "\n",
    "A potential bias to consider would arise from an uneven distribution of categorized shoes, which may result in certain shoes and shoe styles having inaccurate predictions or irrelevant recommendations. This of course, would make our model less reliable and discourage people with diverse styles from using it. Thus, it will be important to utilize an evenly distributed and representative dataset for this project. Because of our limited time to execute on this project we will likely be scoping our project down to a specific style of shoe to test the validity of our model and include this caveat in our readme and final project submission. In a similar vein, we will not be able to create a search algorithm that can scrape for prices off of every website and social media listing online so our resulting recommendations will be from larger resale or retail sites that consolidate many shoe types and prices in the same place, further biasing our results. The resulting reported prices of shoes are not to be taken as true financial advice as this is not a final product for market but rather an academic project to learn how to apply machine learning techniques.  \n",
    "\n",
    "Careful consideration through precise exploratory data analysis will help us cater to these potential biases and also expose any new biases that arise during the span of our project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put things here that cement how you will interact/communicate as a team, how you will handle conflict and difficulty, how you will handle making decisions and setting goals/schedule, how much work you expect from each other, how you will handle deadlines, etc...\n",
    "* *Be present mentally when meeting, and clearly articulate blockers*\n",
    "* *Build off of ideas instead of tearing them down*\n",
    "* *Understand and respect each others' preferences for communication, and clearly articulate own preferences*\n",
    "* *Uphold standards of integrity and quality when developing code, citing sources used*\n",
    "* *Create an environment where people are comfortable reaching out for help*\n",
    "* *Reach out for help as soon as possible when it is needed, and treat everyone and their tasks as equally important to the success of the team*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with something meaningful that is appropriate for your needs. It doesn't have to be something that fits this format.  It doesn't have to be set in stone... \"no battle plan survives contact with the enemy\". But you need a battle plan nonetheless, and you need to keep it updated so you understand what you are trying to accomplish, who's responsible for what, and what the expected due dates are for each item.\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 2/19  |  6:30 PM |  Do background research on topic and narrow the scope of the project (all)  | Discuss ideal dataset(s) and ethics; draft project proposal, begin background research | \n",
    "| 2/20  |  6 PM |  Edit, finalize, and submit proposal; Search for datasets and find sites can use web scraper on  if not enough data (all) | Discuss ideal dataset(s) and ethics; draft project proposal | \n",
    "| 2/24  | 10 PM  | Import & Wrangle Data, web scraper built and run (Mabel), start on EDA run images with background through the CNN (Ray)  | Review/Edit wrangling/EDA; Discuss Analysis Plan |\n",
    "| 3/2  | 6 PM  | Finalize wrangling/EDA; program the clustering algorithm (Joshua and Sialoi) | Review/Edit wrangling/EDA; Discuss Analysis Plan   |\n",
    "| 3/9  | 6 PM  | Finalize wrangling/EDA; program the search algorithm and validate the clustering algorithm (all) | Discuss/edit project code; Complete project |\n",
    "| 3/16  | 6 PM  | Complete analysis; Draft results/conclusion/discussion (all)| Discuss/edit full project |\n",
    "| 3/19  | Before 11:59 PM  | NA | Turn in Final Project  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"lorenznote\"></a>1.[^](#lorenz): Lorenz, T. (9 Dec 2021) Birds Aren’t Real, or Are They? Inside a Gen Z Conspiracy Theory. *The New York Times*. https://www.nytimes.com/2021/12/09/technology/birds-arent-real-gen-z-misinformation.html<br> \n",
    "<a name=\"admonishnote\"></a>2.[^](#admonish): Also refs should be important to the background, not some randomly chosen vaguely related stuff. Include a web link if possible in refs as above.<br>\n",
    "<a name=\"sotanote\"></a>3.[^](#sota): Perhaps the current state of the art solution such as you see on [Papers with code](https://paperswithcode.com/sota). Or maybe not SOTA, but rather a standard textbook/Kaggle solution to this kind of problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
