{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: umap-learn in /home/mszeto/.local/lib/python3.9/site-packages (0.5.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from umap-learn) (1.22.4)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /home/mszeto/.local/lib/python3.9/site-packages (from umap-learn) (0.5.11)\n",
      "Requirement already satisfied: numba>=0.51.2 in /opt/conda/lib/python3.9/site-packages (from umap-learn) (0.53.1)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /opt/conda/lib/python3.9/site-packages (from umap-learn) (0.24.2)\n",
      "Requirement already satisfied: scipy>=1.3.1 in /opt/conda/lib/python3.9/site-packages (from umap-learn) (1.7.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from umap-learn) (4.61.2)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /opt/conda/lib/python3.9/site-packages (from numba>=0.51.2->umap-learn) (0.36.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from numba>=0.51.2->umap-learn) (49.6.0.post20210108)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.9/site-packages (from pynndescent>=0.5->umap-learn) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn>=0.22->umap-learn) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-19 04:21:34.528050: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# things we will need to do stuff in this notebook\n",
    "%pip install umap-learn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from numpy.linalg import norm\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from umap import UMAP\n",
    "from sklearn.manifold import TSNE\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "# two useful data viz libraries\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "\n",
    "# setup plotting in a notebook in a reasonable way\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "# default figure aesthetics I'll be using, \n",
    "# there are other choices, see seaborn docs\n",
    "#sns.set_style(\"white\")\n",
    "#sns.set_context(\"notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_collection shape is: (1, 13872)\n",
      "Inside folder 1: Reebok\n",
      "Inside folder 2: Converse\n",
      "Inside folder 3: Amiana\n",
      "Inside folder 4: AlexanderMcQueen\n",
      "Inside folder 5: SKECHERS\n",
      "Inside folder 6: ALDO\n",
      "Inside folder 7: Lacoste\n",
      "Inside folder 8: adidasY-3\n",
      "Inside folder 9: UGG\n",
      "Inside folder 10: AdidasOriginals\n",
      "Inside folder 11: Crocs\n",
      "Inside folder 12: KangaROOS\n",
      "Inside folder 13: BetseyJohnson\n",
      "Inside folder 14: Nike\n"
     ]
    }
   ],
   "source": [
    "# Default parameters of the images\n",
    "default_width = 136\n",
    "default_length = 102\n",
    "default_dimension = default_width * default_length # this change is for the grayscale to work \n",
    "num_of_channels = 3\n",
    "default_color_dimension = default_width * default_length * num_of_channels\n",
    "\n",
    "#default_dimension = 35625\n",
    "\n",
    "# Load in all of the images stored in the sneakers folder\n",
    "# Define the collection of images\n",
    "image_collection = np.zeros((1, default_dimension))\n",
    "color_image_collection = np.zeros((1, default_color_dimension))\n",
    "print(f\"image_collection shape is: {image_collection.shape}\")\n",
    "# Pathway to the main folder that holds all types of shoes\n",
    "main_path = \"./sneakers\"\n",
    "# Makes a list of folder names found in the main folder\n",
    "folders = os.listdir(main_path)\n",
    "# Iterates through those folder names\n",
    "for i, folder in enumerate(folders):\n",
    "    # Keeps track of progress of folder dive\n",
    "    print(f\"Inside folder {i+1}: {folder}\")\n",
    "    # Creates the pathway to the folder inside the main folder \n",
    "    folder_path = os.path.join(main_path, folder)\n",
    "    # List all files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "    # Iterate through all of the files and add them to the collection of flattened images\n",
    "    for file in files:\n",
    "        # Creates the pathway to the images inside the folder\n",
    "        image_path = os.path.join(folder_path, file)\n",
    "        # Loads the images into the notebook as a list and then changes it to a numpy array\n",
    "        image_list = Image.open(image_path)\n",
    "        image_color_np = np.array(image_list)\n",
    "        #print(image_color_np.shape)\n",
    "        image_gray = image_list.convert('L')  # Convert to grayscale\n",
    "        image_np = np.array(image_gray)\n",
    "\n",
    "        #image_np = np.array(image_list)\n",
    "        # Remove rows and columns\n",
    "        # rows_to_delete = [0, 1, 2, -1, -2, -3, -4]\n",
    "        # cols_to_delete = [0, 1, 2, 3, 4, 5, -1, -2, -3, -4, -5]\n",
    "        # image_np = np.delete(image_np, rows_to_delete, axis=0)\n",
    "        # image_np = np.delete(image_np, cols_to_delete, axis=1)\n",
    "        #temp comment it out for the grayscale stuff to work \n",
    "        \n",
    "        # Flatten the image\n",
    "        image_flat = image_np.reshape(1, -1)\n",
    "        color_image_flat = image_color_np.reshape(1, -1)\n",
    "        # If this is the first image, index instead of stack inside the collection\n",
    "        if i == 0:\n",
    "            image_collection[0] = image_flat\n",
    "            color_image_collection[0] = color_image_flat\n",
    "        else:\n",
    "            image_collection = np.vstack((image_collection, image_flat))\n",
    "            color_image_collection = np.vstack((color_image_collection, color_image_flat))\n",
    "# for loop ends here\n",
    "print(f\"image_collection shape is: {image_collection.shape}\")\n",
    "print(f\"color_image_collection shape is: {color_image_collection.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_collection[0, 5000:5200])\n",
    "#plt.imshow(image_collection[0].astype(int).reshape((95, 125, 3)))\n",
    "# was giving error when running with the greyscale code so i skipped it \n",
    "plt.imshow(image_collection[0].reshape((default_length, default_width)), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "# Because of the curse of dimensionality, we'll use UMAP to reduce the dimensionality\n",
    "image_collection_mean = np.mean(image_collection, axis=0, keepdims=True)\n",
    "print(f\"image_collection_mean shape: {image_collection_mean.shape}\")\n",
    "\n",
    "# Mean centered data\n",
    "mean_centered_data = image_collection - image_collection_mean\n",
    "\n",
    "n_components = 2\n",
    "umap_v1 = UMAP(n_neighbors=15, n_components=n_components*50, random_state=99, min_dist=0.05) #lowered the n_neighbors from 40 and the min_dist from 0.07\n",
    "tsne_v1 = TSNE(n_components=n_components,perplexity=60,random_state=99)\n",
    "reduced_image_collection = umap_v1.fit_transform(mean_centered_data)\n",
    "reduced_image_collection = tsne_v1.fit_transform(reduced_image_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 50 #started at 20 and have increased\n",
    "clustering = AgglomerativeClustering(n_clusters=num_clusters, linkage='ward')  \n",
    "cluster_labels = clustering.fit_predict(reduced_image_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cluster_labels[:800])\n",
    "print(len((np.unique(cluster_labels))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_number_of_clusters = max(cluster_labels)+1  # Get the maximum cluster label\n",
    "cluster_to_samples = {}\n",
    "\n",
    "for elem in cluster_labels:\n",
    "    if elem in cluster_to_samples:\n",
    "        cluster_to_samples[elem] += 1\n",
    "    else:\n",
    "        cluster_to_samples[elem] = 1\n",
    "\n",
    "print(f\"The max number of clusters found were: {max_number_of_clusters}\")  # Add 1 to account for cluster labels starting from 0\n",
    "print(cluster_to_samples)\n",
    "# Be careful about the clusters that only have 1 data sample to it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find Centroids\n",
    "def find_centroids(labels, num_of_clusters, data):\n",
    "    cluster_means = np.zeros((num_of_clusters, 2))\n",
    "    for i in range(num_of_clusters):  # Start from 0 and iterate up to num_of_clusters - 1\n",
    "        # Finds the points associated with cluster i\n",
    "        indices = labels == i\n",
    "        cluster_means[i] = np.sum(data[indices, :], axis=0) / np.sum(indices)\n",
    "    return cluster_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = find_centroids(cluster_labels, max_number_of_clusters, reduced_image_collection)\n",
    "print(centroids.shape)\n",
    "print(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_clusters(umap_embeddings, cluster_labels,centroids):\n",
    " \n",
    "    num_clusters = len(np.unique(cluster_labels))\n",
    "    \n",
    "    colors = plt.cm.get_cmap('tab20', num_clusters)\n",
    "    \n",
    "    # Create a scatter plot of the UMAP embeddings with each cluster colored differently\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for i, cluster_label in enumerate(np.unique(cluster_labels)):\n",
    "        plt.scatter(umap_embeddings[cluster_labels == cluster_label, 0], \n",
    "                    umap_embeddings[cluster_labels == cluster_label, 1], \n",
    "                    label=f'Cluster {cluster_label}', color=colors(i))\n",
    "    for i in range(num_clusters):\n",
    "        plt.scatter(centroids[i, 0], centroids[i, 1], color='black', marker='x', s=100)\n",
    "        plt.text(centroids[i, 0], centroids[i, 1], f'Centroid {i}', fontsize=10, verticalalignment='bottom')\n",
    "\n",
    "    plt.title('Clusters Visualization')\n",
    "    plt.xlabel('UMAP Dimension 1')\n",
    "    plt.ylabel('UMAP Dimension 2')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_clusters(reduced_image_collection, cluster_labels,centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_image_preprocesser(pathway, umap_arg, tsne_arg):\n",
    "    # Loads the images into the notebook as a list and then changes it to a numpy array\n",
    "    image_list = Image.open(pathway)\n",
    "    display(image_list)\n",
    "    \n",
    "    image_gray = image_list.convert('L')  # Convert to grayscale\n",
    "    image_np = np.array(image_gray)\n",
    "        \n",
    "    #image_np = np.array(image_list)\n",
    "    # Remove rows and columns, comment out this whole section for the greyscale to work\n",
    "  #  rows_to_delete = [0, 1, 2, -1, -2, -3, -4]\n",
    "  #  cols_to_delete = [0, 1, 2, 3, 4, 5, -1, -2, -3, -4, -5]\n",
    "  #  image_np = np.delete(image_np, rows_to_delete, axis=0)\n",
    "  #  image_np = np.delete(image_np, cols_to_delete, axis=1)\n",
    "  #  print(f\"Image Shape: {image_np.shape}\")\n",
    "    # Image truncated shape: (95, 125, 3)\n",
    "    \n",
    "    # Flatten the image\n",
    "    image_flat = image_np.reshape(1, -1) # (1, 200)\n",
    "    #image_flat = umap_arg.transform(image_flat)\n",
    "    #image_flat = tsne_arg.transform(image_flat)\n",
    "    return image_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cluster_label(umap_embedding, clustering_model):\n",
    "    # Use the trained clustering model to predict the cluster label for the UMAP embedding\n",
    "    cluster_label = clustering_model.fit_predict(umap_embedding.reshape(1, -1))\n",
    "    return cluster_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'input_image_path' is the path to the input image\n",
    "input_image = input_image_preprocesser(\"sneakers/Reebok/7975411.355043.jpg\",umap_v1, tsne_v1)\n",
    "centered_input = input_image - image_collection_mean\n",
    "umap_embedding_input = np.expand_dims(centered_input, axis=0)\n",
    "umap_embedding_input = umap_embedding_input[0]\n",
    "umap_embeddings_combined = np.concatenate((mean_centered_data, umap_embedding_input), axis=0)\n",
    "\n",
    "umap_embeddings_combined = umap_v1.fit_transform(umap_embeddings_combined)\n",
    "umap_embeddings_combined = tsne_v1.fit_transform(umap_embeddings_combined)\n",
    "\n",
    "#umap_embeddings_combined = np.concatenate((reduced_image_collection, input_image), axis=0)\n",
    "cluster_labels = clustering.fit_predict(umap_embeddings_combined)\n",
    "predicted_cluster_label = cluster_labels[-1]\n",
    "print(\"Predicted Cluster Label:\", predicted_cluster_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_indices = np.where(cluster_labels == predicted_cluster_label)[0]\n",
    "print((len(cluster_indices)))\n",
    "# Randomly select three indices from the cluster (excluding the input image)\n",
    "import random\n",
    "random_indices = random.sample(list(cluster_indices), min(3, len(cluster_indices)))\n",
    "\n",
    "print(image_collection[random_indices[0]])\n",
    "\n",
    "for i in random_indices:\n",
    "    \n",
    "    #plt.imshow((image_collection[i].reshape((95, 125, 3))).astype(int))\n",
    "    plt.imshow(color_image_collection[i].reshape((102, 136, 3)).astype(int))#new image size reshape for the grayscale\n",
    "\n",
    "    plt.axis('off')  # Turn off axis\n",
    "    plt.show()\n",
    "\n",
    "print(\"Selected Images from the Cluster:\", random_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import silhouette_samples\n",
    "\n",
    "def plot_silhouette_score(umap_embedding, labels):\n",
    "    silhouette_scores = silhouette_samples(umap_embedding, labels)\n",
    "    silhouette_avg = silhouette_score(umap_embedding, labels)\n",
    "    \n",
    "    # Create a subplot with 1 row and 1 column\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    fig.set_size_inches(10, 15)\n",
    "    y_lower = 10\n",
    "    \n",
    "    for i in range(len(set(labels))):\n",
    "        # Aggregate the silhouette scores for samples belonging to cluster i\n",
    "        ith_cluster_silhouette_values = silhouette_scores[labels == i]\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = plt.cm.nipy_spectral(float(i) / len(set(labels)))\n",
    "        ax.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  \n",
    "\n",
    "    ax.set_title(\"Silhouette plot\")\n",
    "    ax.set_xlabel(\"Silhouette coefficient values\")\n",
    "    ax.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax.set_yticks([]) \n",
    "    ax.set_xticks([-0.4, -0.2, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_silhouette_score(umap_embeddings_combined, cluster_labels)\n",
    "\n",
    "silhouette_avg = silhouette_score(umap_embeddings_combined, cluster_labels)\n",
    "print(\"Silhouette Score:\", silhouette_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
