{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118B - Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Jay Buensuceso\n",
    "- Mabel Szeto\n",
    "- Joshua Lapidario\n",
    "- Sialoi Taa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "We will be making a shoe detection model that would identify the shoe, then return the lowest price of it based on the popular shops online. The problem is handled two ways, an image classification neural network such as VCCNet would determine what kind of shoe it is. We then run some sort of clustering on it to cluster it based on whatever hyperparameter we decide on (i.e. brand, shoe type, etc.). Those parameters would be used to search for that specific pair online and return the cheapest cost for that pair of shoes. The cost portion would be a search algorithm/scrape on a set of sites. The clustering idea is there so it fits within the requirements of using unsupervised learning, but also further exploring any hidden similarities and contrasts between different shoes and shoe types beyond the context of supervised labeling. We are measuring accuracy by comparing our results with the actual price. For our unsupervised learning method, we will take into account the Rand Index and Adjusted Rand Index scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "At the core, this project explores the many capabilities of machine learning and computer vision. Fashion styles, more specifically with regards to shoes in this context, are popular ways for people to express themselves in modern society. With AI being the hot topic being discussed as well, it should come to no surprise that it can be applied to the context of fashion. Visual search for specific items of clothing and product recommendation systems have been developed for the market in recent years. There are a plethora of examples of this application in academia as well <a name=\"zakaryan\"></a>[<sup>[1]</sup>](#zakaryannote).\n",
    "\n",
    "There are a plethora of examples of this application in both industry and academia. In one instance, Modista, a computer vision and machine learning based retail recommendation service, relies on the three features of shape, texture, and color to provide recommendations for similar shoes. In a study by Borras et al. through a UAB Bellaterra research paper “High-Level Clothes Description based on Colour-Texture and Structural Features”, the authors interpreted five clothing combinations in a graphical manner to try to deduce what someone was wearing in an inputted image. Both of these cases yield interesting insight into machine learning for fashion applications, but are fairly simple in nature <a name=\"khosla\"></a>[<sup>[2]</sup>](#khoslanote). \n",
    "\n",
    "A more complex application involving the use of Convolution Neural Networks (CNNs), and which we are taking inspiration from in our own project, comes from a Stanford research paper by Khosla and Venkataraman entitled “Building Image-Based Shoe Search Using Convolutional Neural Networks”.[1] CNNs are a popular form of neural networks used in image classification by using the mathematical property of convolution to simplify computations during model training. In summary, the method they used involved splitting the steps into a Classification problem and a Retrieval problem. During classification, the authors relied on fine-tuning the different parts of their CNN model through a withheld validation set. The retrieval aimed to use L2 distance as a measure of similarity between images. The authors struggled here in regards to the nature of retrieval being inherently subjective in comparison to the classification (because there is no concrete definition for a shoe to be “similar” to another shoe). In the end, the authors found that they were able to improve over traditional computer vision and machine learning techniques through the use of their deep learning CNN architectures <a name=\"khosla\"></a>[<sup>[2]</sup>](#khoslanote). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "We are making a project to help you when you identify a pair of shoes but don’t know the name of them and want to know the cheapest price those shoes can be bought at. The algorithm will take pictures of shoes as input. We will use a clustering algorithm to filter out images that our neural network cannot handle. We will be utilizing an image classification neural network such as VCCNet to determine what kind of shoe it is. The identified shoe type and brand will be inserted into a search algorithm in order to optimize what sites it will look at, from the resulting sites we can scrape for prices and compare to find the lowest price from resale or the manufacturer's suggested retail price (msrp)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "- https://www.kaggle.com/datasets/die9origephit/nike-adidas-and-converse-imaged  The dataset contains 2 folders: one with the test data and the other one with training data. The test dataset contains 114 images and the training dataset contains 711 images. The images have a resolution of 240x240 pixels in RGB color model. Both the folders contain 3 classes: Adidas, Converse, and Nike, and have the same number of images per brand. Image content varies by the number of shoes, background, orientation, and some are being worn in the picture. \n",
    "- https://www.kaggle.com/datasets/ifeanyinneji/nike-adidas-shoes-for-image-classification-dataset/data The dataset contains 3 folders: test, train, and validation data. All folders contain 2 classes: adidas and nike. 30 images of shoes from each brand for testing, 230 images from each brand for training, 27 images for Adidas shoes and 28 Nike for the validation. Some of the images have backgrounds and some only have white in the background, orientation of shoes in the images vary. This set also comes with labels for the images in a csv.\n",
    "- https://www.kaggle.com/datasets/utkarshsaxenadn/shoes-classification-dataset-13k-images  The dataset has 5 classes: ballet flat, boat shoes, brogues, clogs, and sneakers. In the test set there are 1,215 images, the training set has 10,000 images, and the validation set has 2,500 images. Images in the dataset vary in orientation, backgrounds vary, some images of the shoes are being worn, and photos have varying numbers of shoes in them.\n",
    "- https://www.kaggle.com/datasets/noobyogi0100/shoe-dataset  This dataset consists of 6 classes of shoes: boots, sneakers, flip flops, loafers, sandals, and soccer shoes. It contains 249 images of each shoe type in the training set and 50 of each type in the validation set. The size of the images is variable but the format of each file is jpeg."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "The first part of our solution involves preprocessing our dataset by clustering our datasets in order to help clean our data by removing outliers and identify relevant features we can use for the input of our neural network such as shoe brand (i.e. Nike, Adidas, Reebok, etc.) or shoe type.\n",
    "\n",
    "\n",
    "Our solution requires the use of image recognition, we plan to utilize a neural network trained on images of shoes. Taking inspiration from “Building Image-Based Shoe Search Using Convolutional” by Khosla et al, we aim to use a well documented convolutional neural network for our image classifier such as Resnet or VGGNet.\n",
    "\n",
    "\n",
    "Our convolutional neural network will utilize PyTorch as its primary library rather than tensorflow. This is due to the fact that there is much more documentation and modern support for PyTorch as opposed to Tensorflow. We also chose to go with the PyTorch due to our group’s experience in working with the library through COGS 185.\n",
    "\n",
    "\n",
    "We finally plan on comparing our solution against the paper “Building Image-Based Shoe Search Using Convolutional” by Khosla et al. as they also created an image based shoe search albeit without clustered datasets. <a name=\"khosla\"></a>[<sup>[2]</sup>](#khoslanote). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "We will be utilizing several evaluation metrics. We will use a validation set to measure accuracy while fine-tuning and optimizing our model. In addition, we will use a test set to measure our model’s accuracy on unseen data. For our unsupervised learning method, we will take into account the Adjusted Rand Index scores. The adjusted rand index score will measure the agreement between two sets of clusterings and account for randomness. The reason for this is because we can see how similar the solution labels are to the predicted labels that were produced by the benchmark model. There’s another evaluation metric we could use named rand index but it wouldn’t provide us with as much information as an adjusted index score. Rand index will tell us how many similar 2 sets of clustering will be but won’t let us know if it was due to randomness or certainty. Adjusted rand index will give us the similarity score between 2 sets of clusterings but will also let us know if the labeling was just random labeling or if they are similar because the model predicted correctly. So we can use the adjusted rand score to measure how well our model predicts a label and if those labels were by chance or if they were by precisely calculated gradient descent methods throughout each epoch.\n",
    "\n",
    "\n",
    "RI = Rand Index Score\n",
    "E = Expectation of the Rand Index Score\n",
    "Adjusted Rand Index Score = (RI - E)/(1-E) This will solve the problem of rand index score being sensitive to chance by accounting for the expectation of the rand index score when calculating the adjusted rand index score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with any computer vision and machine learning problem, we need to be considerate with the consent and privacy of any individuals appearing within or affiliated with the dataset. We will ensure that the data we use for our project does not infringe upon anyone’s privacy or personal information, such as excluding faces and any indicators of personal addresses or locations from images we obtain. We will not be scraping data from sites that have a paywall, require password login to view, or any sites that restrict this type of data collection in their terms of service. The images and data that we will be scraping for are publicly accessible on the internet. We will be scraping only for the initial data collection part of our project to minimize load on the website's servers and spread the volume that we scrape across different sites to avoid disrupting the service for other users. We are not making generative AI that creates new images from the images in our datasets.\n",
    "\n",
    "A potential bias to consider would arise from an uneven distribution of categorized shoes, which may result in certain shoes and shoe styles having inaccurate predictions or irrelevant recommendations. This of course, would make our model less reliable and discourage people with diverse styles from using it. Thus, it will be important to utilize an evenly distributed and representative dataset for this project. Because of our limited time to execute on this project we will likely be scoping our project down to a specific style of shoe to test the validity of our model and include this caveat in our readme and final project submission. In a similar vein, we will not be able to create a search algorithm that can scrape for prices off of every website and social media listing online so our resulting recommendations will be from larger resale or retail sites that consolidate many shoe types and prices in the same place, further biasing our results. The resulting reported prices of shoes are not to be taken as true financial advice as this is not a final product for market but rather an academic project to learn how to apply machine learning techniques.  \n",
    "\n",
    "Careful consideration through precise exploratory data analysis will help us cater to these potential biases and also expose any new biases that arise during the span of our project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put things here that cement how you will interact/communicate as a team, how you will handle conflict and difficulty, how you will handle making decisions and setting goals/schedule, how much work you expect from each other, how you will handle deadlines, etc...\n",
    "* *Be present mentally when meeting, and clearly articulate blockers*\n",
    "* *Build off of ideas instead of tearing them down*\n",
    "* *Understand and respect each others' preferences for communication, and clearly articulate own preferences*\n",
    "* *Uphold standards of integrity and quality when developing code, citing sources used*\n",
    "* *Create an environment where people are comfortable reaching out for help*\n",
    "* *Reach out for help as soon as possible when it is needed, and treat everyone and their tasks as equally important to the success of the team*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with something meaningful that is appropriate for your needs. It doesn't have to be something that fits this format.  It doesn't have to be set in stone... \"no battle plan survives contact with the enemy\". But you need a battle plan nonetheless, and you need to keep it updated so you understand what you are trying to accomplish, who's responsible for what, and what the expected due dates are for each item.\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 2/19  |  6:30 PM |  Do background research on topic and narrow the scope of the project (all)  | Discuss ideal dataset(s) and ethics; draft project proposal, begin background research | \n",
    "| 2/20  |  6 PM |  Edit, finalize, and submit proposal; Search for datasets and find sites can use web scraper on  if not enough data (all) | Discuss ideal dataset(s) and ethics; draft project proposal | \n",
    "| 2/24  | 10 PM  | Import & Wrangle Data, web scraper built and run (Mabel), start on EDA run images with background through the CNN (Ray)  | Review/Edit wrangling/EDA; Discuss Analysis Plan |\n",
    "| 3/2  | 6 PM  | Finalize wrangling/EDA; program the clustering algorithm (Joshua and Sialoi) | Review/Edit wrangling/EDA; Discuss Analysis Plan   |\n",
    "| 3/9  | 6 PM  | Finalize wrangling/EDA; program the search algorithm and validate the clustering algorithm (all) | Discuss/edit project code; Complete project |\n",
    "| 3/16  | 6 PM  | Complete analysis; Draft results/conclusion/discussion (all)| Discuss/edit full project |\n",
    "| 3/19  | Before 11:59 PM  | NA | Turn in Final Project  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"zakaryannote\"></a>1.[^](#zakaryan):  Zakaryan, Vahan. “AI Clothing Detection: Use Cases for Fashion and E-Commerce.” *Postindustria*, 17 June 2022, https://postindustria.com/ai-clothing-detection-use-cases-for-fashion-and-e-commerce/\n",
    "<br>\n",
    "\n",
    "<a name=\"khoslanote\"></a>2.[^](#khosla): Khosla, Neal and Venkataraman Vignesh. “Building Image-Based Shoe Search Using Convolutional Neural Networks\" *Cs231n.Stanford.Edu,* 2015, http://cs231n.stanford.edu/reports/2015/pdfs/nealk_final_report.pdf\n",
    "<br> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
